[TOC]

# MapReduce流程

## 1 MR详细流程

![1597668966723](../picture/1597668966723.png)

![1597669306762](../picture/1597669306762.png)

## 2 HadoopMapReduc的Shuffle阶段

Hadoop MapReduce 的 Shuffle 阶段是指从 Map 的输出开始，包括系统执行排序，以及传送 Map 输出到 Reduce 作为输入的过程。
排序阶段是指对 Map 端输出的 Key 进行排序的过程。不同的 Map 可能输出相同的 Key，相同的 Key 必须发送到同一个 Reduce 端处理。Shuffle 阶段可以分为 Map 端的 Shuffle 阶段和 Reduce 端的 Shuffle 阶段。Shuffle 阶段的工作过程，如图 2所示

![1597210031120](../picture/1597210031120.png)

### 2.1 Map端的Shuffle阶段

1. 每个输入分片会让一个 Map 任务来处理，默认情况下，以 HDFS 的一个块的大小（默认为 64MB）为一个分片。Map 函数开始产生输出时，并不是简单地把数据写到磁盘中，因为频繁的磁盘操作会导致性能严重下降。它的处理过程是把数据首先写到内存中的一个缓冲区， 并做一些预排序，以提升效率。
2. 每个 Map 任务都有一个用来写入输出数据的循环内存缓冲区（默认大小为 100MB)，当缓冲区中的数据量达到一个特定阈值（默认是 80%）时，系统将会启动一个后台线程，把缓冲 区中的内容写到磁盘中（即 Spill 阶段)。在写磁盘过程中，Map 输出继续被写到缓冲区中，但如果在此期间缓冲区被填满，那么 Map 任务就会阻塞直到写磁盘过程完成。
3. 在写磁盘前，线程首先根据数据最终要传递到的 Reduce 任务把数据划分成相应的分区（Partition）。在每个分区中，后台线程按 Key 进行排序，如果有一个 Combiner，便会在排序后 的输出上运行。
4. 一旦内存缓冲区达到溢出写的阈值，就会创建一个溢出写文件，因此在 Map 任务完成其最后一个输出记录后，便会有多个溢出写文件。在 Map 任务完成前，溢出写文件被合并成一个索引文件和数据文件（多路归并排序）（Sort 阶段)。
5. 溢出写文件归并完毕后，Map 任务将删除所有的临时溢出写文件，并告知 TaskTracker 任务已完成，只要其中一个 Map 任务完成，Reduce 任务就会开始复制它的输出（Copy 阶段)。
6. Map 任务的输出文件放置在运行 Map 任务的 TaskTracker 的本地磁盘上，它是运行 Reduce 任务的 TaskTracker 所需要的输入数据。

### 2.2 Reduce端的Shuffle阶段

1. Reduce 进程启动一些数据复制线程，请求 Map 任务所在的 TaskTracker 以获取输出文件（Copy 阶段）。
2. 将 Map 端复制过来的数据先放入内存缓冲区中，Merge 有 3 种形式，分别是内存到内存，内存到磁盘，磁盘到磁盘。默认情况下，第一种形式不启用，第二种形式一直在运行（Spill 阶段），直到结束，第三种形式生成最终的文件（Merge 阶段）。
3. 最终文件可能存在于磁盘中，也可能存在于内存中，但是默认情况下是位于磁盘中的。当 Reduce 的输入文件已定，整个 Shuffle 阶段就结束了，然后就是 Reduce 执行，把结果放到 HDFS 中（Reduce 阶段）。

## 3 总结

### 3.1 map的输入阶段

前提：HDFS上传的文件，会按大小进行切块（按字节数切）。

HDFS在做数据切割的时候，可能会将数据切割在上下两个块的尾和头，为了**保证数据的完整性**，需要把下一个块的头数据还给上一个块，所以除第一个块其余的块都不处理自己的首行数据，并且每一个块会读取下一个块的首行数据。

为了不破坏数据的完整性，hadoop框架具体细节如下：

- 除第一个切片，其余的每个切片在计算自己的块偏移量的**起始位置**的时候都会将偏移量**下移一行的字节数**(注意这里是一行)，也就是说除第一个切片，剩余的切片都不会处理自己的首行数据。
- 每一个块会读取下一个块的首行数据。

### 3.2 map的输出阶段

- map读取的数据会放到**环形缓冲区**(默认是100M，溢写阈值是0.8)，
- 当缓冲区的数据量达到溢写阈值后会另起一个线程将阈值之前的数据先在内存中进行**快速排序**（！！！唯一从无序到有序的地方），如果这里配置了combiner，这里会进行一次combiner操作，将数据压小(即合并)，然后写到磁盘，
- 当然在溢写的过程中，后续的数据可以继续往后面的缓冲区空间写，如果这部分空间写满了，那么读取数据的线程就会阻塞，等到溢写线程完成工作(即腾出空间)后，继续开始数据的读取。
- 如果开启了combiner，并且生成的溢写文件数>=3，那么这里会再进行一次combiner操作，将数据再次合并。

环形缓冲区以及原理（**经典**）：见[bilibili视频 - map-output原理-环形缓冲区](https://www.bilibili.com/video/BV1Nb411P7Mf?p=54)视频的43:02开始。

- KV对的存储（KVP：key/value/分区号）
- 索引信息，索引中存放了哪些信息
- 为什么叫环形缓冲区
- 快排其实是对索引进行排序

<img src="picture/1611480211888.png" alt="1611480211888" style="zoom:80%;" />

### 3.3 reduce阶段

1. 拉取map的结果数据
2. 做merge操作，归并排序
3. 迭代器，同一个reduce中的数据怎么区分是不同的组（读取下一条数据，如果是相同的key则是一组，否则是一个新的组）

## PS-相关资料

- [MR原理](https://zhuanlan.zhihu.com/p/85666077)
- [bilibili视频 - map-input原理-切片保证数据完整性](https://www.bilibili.com/video/BV1Nb411P7Mf?p=53)
- [bilibili视频 - map-output原理-环形缓冲区](https://www.bilibili.com/video/BV1Nb411P7Mf?p=54)
- [bilibili视频 - reduce原理](https://www.bilibili.com/video/BV1Nb411P7Mf?p=55)
